{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7aa7f46749d44be68a773833b916461b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_54037490e74d44e59cb57bed7e8f4a36",
              "IPY_MODEL_ed9f41ab4da84a0c951f51d806e07b8e",
              "IPY_MODEL_5e8373f124f04db0855d782f4d289239"
            ],
            "layout": "IPY_MODEL_fe54a6a830494039af4028e429cdd73b"
          }
        },
        "54037490e74d44e59cb57bed7e8f4a36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f20b8feccd0f4839ba0ab6534ecaa300",
            "placeholder": "​",
            "style": "IPY_MODEL_e9124659dced4532bf2876b4d3daf979",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "ed9f41ab4da84a0c951f51d806e07b8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30f782e1a43649529423f2b8b3bb966e",
            "max": 213450,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d49fb22c760c4e68a7c43ea9dc2c3ee4",
            "value": 213450
          }
        },
        "5e8373f124f04db0855d782f4d289239": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d54ec2abef70485bb2df74fff37d11bd",
            "placeholder": "​",
            "style": "IPY_MODEL_7268d0536aa247b6b44347c7f1f38d6f",
            "value": " 213k/213k [00:00&lt;00:00, 307kB/s]"
          }
        },
        "fe54a6a830494039af4028e429cdd73b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f20b8feccd0f4839ba0ab6534ecaa300": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9124659dced4532bf2876b4d3daf979": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "30f782e1a43649529423f2b8b3bb966e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d49fb22c760c4e68a7c43ea9dc2c3ee4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d54ec2abef70485bb2df74fff37d11bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7268d0536aa247b6b44347c7f1f38d6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c5cac444bfb24317a2c5301ab7678da7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_11107fa45daf4523a4f5eb1bd7766fc9",
              "IPY_MODEL_e6af404384484b4c908f6f719f068c5c",
              "IPY_MODEL_94aeaeee42b549508827f4b23b94a28b"
            ],
            "layout": "IPY_MODEL_4ad18e93c5d2445d9aa5457ee1faa09a"
          }
        },
        "11107fa45daf4523a4f5eb1bd7766fc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a3bdc7a32c9439aa1cadde5897b11d5",
            "placeholder": "​",
            "style": "IPY_MODEL_a5c3dc46b1764d1d8ccd10bd7d64fb6c",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "e6af404384484b4c908f6f719f068c5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e51abbd4db2843e0b6836fd7a81b4203",
            "max": 29,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_988c3e9ed9c0462588a5d0c9f4408153",
            "value": 29
          }
        },
        "94aeaeee42b549508827f4b23b94a28b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_552f23eaa16a40cf8623f7c511f52f51",
            "placeholder": "​",
            "style": "IPY_MODEL_921de3deb9d444d1a8363c25339eae26",
            "value": " 29.0/29.0 [00:00&lt;00:00, 1.55kB/s]"
          }
        },
        "4ad18e93c5d2445d9aa5457ee1faa09a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a3bdc7a32c9439aa1cadde5897b11d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5c3dc46b1764d1d8ccd10bd7d64fb6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e51abbd4db2843e0b6836fd7a81b4203": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "988c3e9ed9c0462588a5d0c9f4408153": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "552f23eaa16a40cf8623f7c511f52f51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "921de3deb9d444d1a8363c25339eae26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56c8510f34da4b85870b3342c184f905": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ad5b90e128ca423ab143e8ce839f33f3",
              "IPY_MODEL_b6a8015ed26d4be6ad39f311e1b8334d",
              "IPY_MODEL_9dbb12b5177c4de2b678cc82b2e0a510"
            ],
            "layout": "IPY_MODEL_00834ebe26664ed4a6dc81b561606193"
          }
        },
        "ad5b90e128ca423ab143e8ce839f33f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d03ac481880740169f7de53a3e7e59e2",
            "placeholder": "​",
            "style": "IPY_MODEL_0e3b570405c34751ae8a7f6e58592c71",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "b6a8015ed26d4be6ad39f311e1b8334d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f545a829589d49aaa74d908b67e886a2",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eab78b8326cd485ca218b4fed8cdc13c",
            "value": 570
          }
        },
        "9dbb12b5177c4de2b678cc82b2e0a510": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69ea48c5e678431b8f4b3c139d27eca0",
            "placeholder": "​",
            "style": "IPY_MODEL_6ff4331b570e48c180e872a17df16882",
            "value": " 570/570 [00:00&lt;00:00, 4.36kB/s]"
          }
        },
        "00834ebe26664ed4a6dc81b561606193": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d03ac481880740169f7de53a3e7e59e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e3b570405c34751ae8a7f6e58592c71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f545a829589d49aaa74d908b67e886a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eab78b8326cd485ca218b4fed8cdc13c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "69ea48c5e678431b8f4b3c139d27eca0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ff4331b570e48c180e872a17df16882": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "34004b60296a46e38982c98e6d4f8b63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_60443817ae97460aa05f41943b39de8b",
              "IPY_MODEL_dd6898a5843644f39566717a37ec1975",
              "IPY_MODEL_c1432969fb7148298b196aadf7fe74d1"
            ],
            "layout": "IPY_MODEL_1fc6a3d585c5442ca38cae44c40d3f70"
          }
        },
        "60443817ae97460aa05f41943b39de8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80d535e3880b46c6a2a142af57c2bba6",
            "placeholder": "​",
            "style": "IPY_MODEL_016dbf5931294e378bee8d9d15b55e26",
            "value": "Downloading (…)&quot;pytorch_model.bin&quot;;: 100%"
          }
        },
        "dd6898a5843644f39566717a37ec1975": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f9131e615a943aaba0cee674f9ad5c4",
            "max": 435779157,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_19f17490d1024b73902d20b70d412757",
            "value": 435779157
          }
        },
        "c1432969fb7148298b196aadf7fe74d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e388a7bff66417e88a1cac39787383a",
            "placeholder": "​",
            "style": "IPY_MODEL_9f755d93755d4ce8a3792688a141b173",
            "value": " 436M/436M [00:02&lt;00:00, 119MB/s]"
          }
        },
        "1fc6a3d585c5442ca38cae44c40d3f70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80d535e3880b46c6a2a142af57c2bba6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "016dbf5931294e378bee8d9d15b55e26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5f9131e615a943aaba0cee674f9ad5c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19f17490d1024b73902d20b70d412757": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0e388a7bff66417e88a1cac39787383a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f755d93755d4ce8a3792688a141b173": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cd16mVVSJBdT",
        "outputId": "a38e5939-9327-4a97-dee6-b8e4fb58e8af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.12.1 tokenizers-0.13.2 transformers-4.26.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.1+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.5.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-0.11.1-py3-none-any.whl (517 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.2/517.2 KB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (4.5.0)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.13.1+cu116)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (23.0)\n",
            "Installing collected packages: torchmetrics\n",
            "Successfully installed torchmetrics-0.11.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting spacy-udpipe\n",
            "  Downloading spacy_udpipe-1.0.0-py3-none-any.whl (11 kB)\n",
            "Collecting ufal.udpipe>=1.2.0\n",
            "  Downloading ufal.udpipe-1.3.0.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (937 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m937.2/937.2 KB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<4.0.0,>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy-udpipe) (3.4.4)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-udpipe) (2.4.5)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-udpipe) (0.10.1)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-udpipe) (8.1.7)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-udpipe) (1.10.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-udpipe) (3.0.12)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-udpipe) (2.0.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-udpipe) (23.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-udpipe) (2.11.3)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-udpipe) (0.7.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-udpipe) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-udpipe) (1.21.6)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-udpipe) (1.0.4)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-udpipe) (0.10.1)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-udpipe) (6.3.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-udpipe) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-udpipe) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-udpipe) (3.0.8)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-udpipe) (2.25.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-udpipe) (4.64.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-udpipe) (57.4.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<4.0.0,>=3.0.0->spacy-udpipe) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->spacy-udpipe) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->spacy-udpipe) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->spacy-udpipe) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->spacy-udpipe) (2.10)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<4.0.0,>=3.0.0->spacy-udpipe) (0.0.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<4.0.0,>=3.0.0->spacy-udpipe) (0.7.9)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.8.0,>=0.3.0->spacy<4.0.0,>=3.0.0->spacy-udpipe) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy<4.0.0,>=3.0.0->spacy-udpipe) (2.0.1)\n",
            "Installing collected packages: ufal.udpipe, spacy-udpipe\n",
            "Successfully installed spacy-udpipe-1.0.0 ufal.udpipe-1.3.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas\n",
        "!pip install transformers\n",
        "!pip install torch\n",
        "!pip install torchmetrics\n",
        "!pip install spacy-udpipe"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from transformers import BertTokenizer, AutoTokenizer, BertForTokenClassification\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torchmetrics\n",
        "from torchmetrics.classification import BinaryF1Score, BinaryPrecisionRecallCurve\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, classification_report\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import transformers\n",
        "import spacy_udpipe\n",
        "import spacy"
      ],
      "metadata": {
        "id": "1CHDdk9vJLGa"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyFPszzaJfAe",
        "outputId": "40f1332a-91cb-406e-8cc6-2132d39b343d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(\"/content/gdrive/MyDrive/bin-prelabeled.csv\")\n",
        "test_df = pd.read_csv(\"/content/gdrive/MyDrive/test-set-bin.csv\")\n",
        "train_data = train_df[\"instance\"]\n",
        "test_data = test_df[\"instance\"]\n",
        "train_labels = train_df[\"bin_transforms\"]\n",
        "test_labels = test_df[\"bin_transforms\"]\n",
        "\n",
        "train_data = train_data.to_numpy()\n",
        "train_labels = train_labels.to_numpy()\n",
        "test_data = test_data.to_numpy()\n",
        "test_labels = test_labels.to_numpy()\n",
        "valid_data = train_data[70000:]\n",
        "valid_labels = train_labels[70000:]\n",
        "train_data = train_data[:70000]\n",
        "train_labels = train_labels[:70000]\n",
        "print(len(train_data), len(train_labels), len(test_data), len(test_labels), len(valid_data), len(valid_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zs2gsxjfJktS",
        "outputId": "2d5e3cbe-deb0-4ae4-98bb-3bde8147c788"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "70000 70000 30000 30000 26265 26265\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "OG45sObLaeIz"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_labels = []\n",
        "testing_labels = []\n",
        "val_labels = []\n",
        "for each in train_labels:\n",
        "  training_labels.append(each.replace(\" \", \"\"))\n",
        "\n",
        "for each in test_labels:\n",
        "  testing_labels.append(each.replace(\" \", \"\"))\n",
        "\n",
        "for each in valid_labels:\n",
        "  val_labels.append(each.replace(\" \", \"\"))\n",
        "\n",
        "training_labels = np.array(training_labels)\n",
        "testing_labels = np.array(testing_labels)\n",
        "val_labels = np.array(val_labels)"
      ],
      "metadata": {
        "id": "dsW77aVr8pa8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = transformers.BertTokenizer.from_pretrained('bert-base-cased')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "7aa7f46749d44be68a773833b916461b",
            "54037490e74d44e59cb57bed7e8f4a36",
            "ed9f41ab4da84a0c951f51d806e07b8e",
            "5e8373f124f04db0855d782f4d289239",
            "fe54a6a830494039af4028e429cdd73b",
            "f20b8feccd0f4839ba0ab6534ecaa300",
            "e9124659dced4532bf2876b4d3daf979",
            "30f782e1a43649529423f2b8b3bb966e",
            "d49fb22c760c4e68a7c43ea9dc2c3ee4",
            "d54ec2abef70485bb2df74fff37d11bd",
            "7268d0536aa247b6b44347c7f1f38d6f",
            "c5cac444bfb24317a2c5301ab7678da7",
            "11107fa45daf4523a4f5eb1bd7766fc9",
            "e6af404384484b4c908f6f719f068c5c",
            "94aeaeee42b549508827f4b23b94a28b",
            "4ad18e93c5d2445d9aa5457ee1faa09a",
            "6a3bdc7a32c9439aa1cadde5897b11d5",
            "a5c3dc46b1764d1d8ccd10bd7d64fb6c",
            "e51abbd4db2843e0b6836fd7a81b4203",
            "988c3e9ed9c0462588a5d0c9f4408153",
            "552f23eaa16a40cf8623f7c511f52f51",
            "921de3deb9d444d1a8363c25339eae26",
            "56c8510f34da4b85870b3342c184f905",
            "ad5b90e128ca423ab143e8ce839f33f3",
            "b6a8015ed26d4be6ad39f311e1b8334d",
            "9dbb12b5177c4de2b678cc82b2e0a510",
            "00834ebe26664ed4a6dc81b561606193",
            "d03ac481880740169f7de53a3e7e59e2",
            "0e3b570405c34751ae8a7f6e58592c71",
            "f545a829589d49aaa74d908b67e886a2",
            "eab78b8326cd485ca218b4fed8cdc13c",
            "69ea48c5e678431b8f4b3c139d27eca0",
            "6ff4331b570e48c180e872a17df16882"
          ]
        },
        "id": "OrPWhZRcYEgP",
        "outputId": "d4db354c-6139-4dda-f69a-dcccf0c32b4a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7aa7f46749d44be68a773833b916461b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c5cac444bfb24317a2c5301ab7678da7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "56c8510f34da4b85870b3342c184f905"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_map = {'0':0, \"1\":1}\n",
        "\n",
        "\n",
        "train_input_ids = []\n",
        "test_input_ids = []\n",
        "val_input_ids = []\n",
        "\n",
        "for tokens in train_data:\n",
        "    input_id = tokenizer.encode(tokens)\n",
        "    train_input_ids.append(input_id)\n",
        "\n",
        "for tokens in test_data:\n",
        "    input_id = tokenizer.encode(tokens)\n",
        "    test_input_ids.append(input_id)\n",
        "\n",
        "for tokens in valid_data:\n",
        "    input_id = tokenizer.encode(tokens)\n",
        "    val_input_ids.append(input_id)\n",
        "\n",
        "\n",
        "train_label_ids = [[label_map[label] for label in labels] for labels in training_labels]\n",
        "test_label_ids = [[label_map[label] for label in labels] for labels in testing_labels]\n",
        "val_label_ids = [[label_map[label] for label in labels] for labels in val_labels]\n",
        "\n",
        "for i, (id, label) in enumerate(zip(train_input_ids, train_label_ids)):\n",
        "    if len(id) > 512:\n",
        "      train_input_ids[i] = id[:512]\n",
        "      train_label_ids[i] = label[:512]\n",
        "\n",
        "for i, (id, label) in enumerate(zip(test_input_ids, test_label_ids)):\n",
        "    if len(id) > 512:\n",
        "      test_input_ids[i] = id[:512]\n",
        "      test_label_ids[i] = label[:512]\n",
        "\n",
        "for i, (id, label) in enumerate(zip(val_input_ids, val_label_ids)):\n",
        "    if len(id) > 512:\n",
        "      val_input_ids[i] = id[:512]\n",
        "      val_label_ids[i] = label[:512]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jo3oKaS4URJ",
        "outputId": "1a9258c9-a705-4970-ce3b-3c55f9b4f23e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (627 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#testing block\n",
        "x = 0\n",
        "print(train_input_ids[x])\n",
        "print(len(train_input_ids[x]))\n",
        "print(\"-----\")\n",
        "print(train_label_ids[x])\n",
        "print(len(train_label_ids[x]))"
      ],
      "metadata": {
        "id": "IZDtECJsTfoP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be2675ab-2777-4834-f41b-b7e7bf6fd57a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[101, 7043, 1116, 1127, 9684, 117, 2094, 16259, 26652, 1105, 2546, 14708, 118, 1107, 2440, 170, 9853, 1590, 1113, 7602, 1150, 1108, 1103, 14708, 2050, 1211, 8362, 23630, 1193, 1825, 146, 1138, 1518, 1518, 1435, 1506, 119, 102]\n",
            "38\n",
            "-----\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "38\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_input_ids = [torch.tensor(seq) for seq in train_input_ids]\n",
        "train_input_ids = nn.utils.rnn.pad_sequence(train_input_ids, batch_first=True)\n",
        "\n",
        "train_label_ids = [torch.tensor(seq) for seq in train_label_ids]\n",
        "train_label_ids = nn.utils.rnn.pad_sequence(train_label_ids, batch_first=True, padding_value = -100)\n",
        "\n",
        "test_input_ids = [torch.tensor(seq) for seq in test_input_ids]\n",
        "test_input_ids = nn.utils.rnn.pad_sequence(test_input_ids, batch_first=True)\n",
        "\n",
        "test_label_ids = [torch.tensor(seq) for seq in test_label_ids]\n",
        "test_label_ids = nn.utils.rnn.pad_sequence(test_label_ids, batch_first=True, padding_value = -100)\n",
        "\n",
        "val_input_ids = [torch.tensor(seq) for seq in val_input_ids]\n",
        "val_input_ids = nn.utils.rnn.pad_sequence(val_input_ids, batch_first=True)\n",
        "\n",
        "val_label_ids = [torch.tensor(seq) for seq in val_label_ids]\n",
        "val_label_ids = nn.utils.rnn.pad_sequence(val_label_ids, batch_first=True, padding_value = -100)\n",
        "\n",
        "\n",
        "# Create attention masks for the train dataset\n",
        "train_attention_masks = []\n",
        "for seq, label in zip(train_input_ids, train_label_ids):\n",
        "    seq_mask = [float(i>0) for i in seq]\n",
        "    train_attention_masks.append(seq_mask)\n",
        "\n",
        "# Create attention masks for the test dataset\n",
        "test_attention_masks = []\n",
        "for seq, label in zip(test_input_ids, test_label_ids):\n",
        "    seq_mask = [float(i>0) for i in seq]\n",
        "    test_attention_masks.append(seq_mask)\n",
        "\n",
        "# Create attention masks for the val dataset\n",
        "val_attention_masks = []\n",
        "for seq, label in zip(val_input_ids, val_label_ids):\n",
        "    seq_mask = [float(i>0) for i in seq]\n",
        "    val_attention_masks.append(seq_mask)"
      ],
      "metadata": {
        "id": "Vz6B0579hU1Q"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_attention_masks = torch.tensor(train_attention_masks)\n",
        "test_attention_masks = torch.tensor(test_attention_masks)\n",
        "val_attention_masks = torch.tensor(val_attention_masks)"
      ],
      "metadata": {
        "id": "ukGhrBPQ9iMD"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_label_ids[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4UFMCJYMhqP",
        "outputId": "9fb48524-aa59-4c5a-c118-df6628558040"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_input_ids.shape, train_label_ids.shape, test_input_ids.shape, test_label_ids.shape, val_input_ids.shape, val_label_ids.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2A5NJt8Qqq2B",
        "outputId": "2bd0ac84-58b0-43db-cd83-2e24b8a3406b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([70000, 321]) torch.Size([70000, 321]) torch.Size([30000, 321]) torch.Size([30000, 321]) torch.Size([26265, 512]) torch.Size([26265, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_input_ids = train_input_ids[:10000]\n",
        "train_attention_masks = train_attention_masks[:10000]\n",
        "train_label_ids = train_label_ids[:10000]\n",
        "test_input_ids = test_input_ids[:4000]\n",
        "test_attention_masks = test_attention_masks[:4000]\n",
        "test_label_ids = test_label_ids[:4000]\n",
        "val_input_ids = val_input_ids[:2000]\n",
        "val_attention_masks = val_attention_masks[:2000]\n",
        "val_label_ids = val_label_ids[:2000]"
      ],
      "metadata": {
        "id": "2ES7xcXFp8pt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_input_ids.shape, train_attention_masks.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTpPjWK7X31Z",
        "outputId": "a1869d2a-e987-498f-935d-dd40a57ec38b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([70000, 321]) torch.Size([70000, 321])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = TensorDataset(train_input_ids, train_attention_masks, train_label_ids)\n",
        "test_dataset = TensorDataset(test_input_ids, test_attention_masks, test_label_ids)\n",
        "val_dataset = TensorDataset(val_input_ids, val_attention_masks, val_label_ids)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=20, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=20, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=20, shuffle=True)"
      ],
      "metadata": {
        "id": "ueOYY2REr7OL"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
      ],
      "metadata": {
        "id": "jrjP_AXA533O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = transformers.BertForTokenClassification.from_pretrained('bert-base-cased', num_labels=2)\n",
        "linear = torch.nn.Linear(784, 2)\n",
        "model.classification_layer = linear\n",
        "loss_fn = torch.nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "epochs = 2\n",
        "temp = 0\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = model.to(device)\n",
        "epoch_losses = []\n",
        "batch_losses = []\n",
        "testing_loss = []\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "    for i, (inputs, attention_masks, labels) in enumerate(train_loader):\n",
        "        model.train()\n",
        "        # Forward pass through the model\n",
        "        inputs, labels, attention_masks = inputs.to(device), labels.to(device), attention_masks.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        #print(inputs.shape)\n",
        "        output = model(inputs, attention_mask=attention_masks, labels=labels)\n",
        "\n",
        "        loss = output.loss\n",
        "        output = output[1]\n",
        "        output = output.argmax(dim=-1)\n",
        "        output = output.float()\n",
        "        output = output.to(device)\n",
        "        \n",
        "        labels = labels.float()\n",
        "        \n",
        "        #print(output.shape, labels.shape)   \n",
        "\n",
        "        # Backward pass and optimization step\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        total_loss += float(loss.item())\n",
        "        batch_losses.append(loss.item())\n",
        "        if (i + 1) % 200 == 0:\n",
        "            print(f\"Loss is: {loss.item()}\")\n",
        "    average_loss = total_loss / (i + 1)\n",
        "    epoch_losses.append(average_loss)\n",
        "\n",
        "        \n",
        "\n",
        "\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    f1_scores = []\n",
        "    f1 = torchmetrics.F1Score(task='binary', num_classes=2).to(device)\n",
        "    for inputs, attention_masks, labels in test_loader:\n",
        "        # Forward pass through the model\n",
        "        inputs, attention_masks, labels = inputs.to(device), attention_masks.to(device), labels.to(device)\n",
        "        \n",
        "        model.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = model(inputs, attention_mask=attention_masks, labels = labels)\n",
        "            loss = output.loss\n",
        "            output = output[1]\n",
        "            output = output.argmax(dim=-1)\n",
        "            output = output.float()\n",
        "            output = output.to(device)\n",
        "            #print(output.shape, labels.shape)\n",
        "\n",
        "            temp_labels = labels[attention_masks == 1]\n",
        "            temp_output = output[attention_masks == 1]\n",
        "            f1.update(temp_labels, temp_output)\n",
        "        \n",
        "        \n",
        "            labels = labels.float()\n",
        "            testing_loss.append(loss)\n",
        "\n",
        "        total += (labels.size(0) * len(labels[0]))\n",
        "        correct += (output == labels).sum()\n",
        "    accuracy = 100 * correct / total\n",
        "    print('Loss: {}. F1: {}'.format(average_loss, f1.compute()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odrImMZf96Lk",
        "outputId": "d941249a-6694-4d06-c388-53c673237936"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss is: 0.012873071245849133\n",
            "Loss is: 0.029962485656142235\n",
            "Loss: 0.016873200391768477. F1: 0.930747926235199\n",
            "Loss is: 0.006991726811975241\n",
            "Loss is: 0.000547347473911941\n",
            "Loss: 0.007937361951131606. F1: 0.9225971102714539\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot:\n",
        "import matplotlib.pyplot as plt\n",
        "print(len(batch_losses))\n",
        "epochs = range(len(batch_losses))\n",
        "plt.figure()\n",
        "plt.plot(epochs, batch_losses, label='Loss')\n",
        "plt.title('Average Vs Epoch')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "elDkBQlw352v",
        "outputId": "25075646-bf64-4850-f0c8-a6b30a11262c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Average Vs Epoch')"
            ]
          },
          "metadata": {},
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot:\n",
        "import matplotlib.pyplot as plt\n",
        "print(len(testing_loss))\n",
        "epochs = range(len(testing_loss))\n",
        "plt.figure()\n",
        "plt.plot(epochs, testing_loss, label='Loss')\n",
        "plt.title('Average Vs Epoch')"
      ],
      "metadata": {
        "id": "uXksgv8FP6a4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), '/content/gdrive/MyDrive/bin_model_v1.pt')"
      ],
      "metadata": {
        "id": "MfQGbKmKJqr2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = transformers.BertForTokenClassification.from_pretrained('bert-base-cased', num_labels=2)\n",
        "linear = torch.nn.Linear(784, 2)\n",
        "model.classification_layer = linear\n",
        "model.load_state_dict(torch.load('/content/gdrive/MyDrive/Copy of bin_model_v1.pt', map_location=torch.device('cpu')))\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158,
          "referenced_widgets": [
            "34004b60296a46e38982c98e6d4f8b63",
            "60443817ae97460aa05f41943b39de8b",
            "dd6898a5843644f39566717a37ec1975",
            "c1432969fb7148298b196aadf7fe74d1",
            "1fc6a3d585c5442ca38cae44c40d3f70",
            "80d535e3880b46c6a2a142af57c2bba6",
            "016dbf5931294e378bee8d9d15b55e26",
            "5f9131e615a943aaba0cee674f9ad5c4",
            "19f17490d1024b73902d20b70d412757",
            "0e388a7bff66417e88a1cac39787383a",
            "9f755d93755d4ce8a3792688a141b173"
          ]
        },
        "id": "ocBIks5AXmJ8",
        "outputId": "76957a91-c3e8-4f51-b7bc-bfd950444b90"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/436M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "34004b60296a46e38982c98e6d4f8b63"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "total = 0\n",
        "correct = 0\n",
        "f1_scores = []\n",
        "f1 = torchmetrics.F1Score(task='binary', num_classes=2).to(device)\n",
        "pr_curve = BinaryPrecisionRecallCurve(thresholds=[0.]).to(device)\n",
        "for i, (inputs, attention_masks, labels) in enumerate(val_loader):\n",
        "        # Forward pass through the model\n",
        "        #print(i)\n",
        "        inputs, labels, attention_masks = inputs.to(device), labels.to(device), attention_masks.to(device)\n",
        "        \n",
        "        output = model(inputs, attention_mask=attention_masks)\n",
        "        loss = output.loss\n",
        "        output = output[0]\n",
        "        output = output.argmax(dim=-1)\n",
        "        output = output.float()\n",
        "        output = output.to(device)\n",
        "        #predictions_np = output.detach().cpu().numpy()\n",
        "        #labels_np = labels.detach().cpu().numpy()\n",
        "                        \n",
        "\n",
        "        # Calculate F1 score\n",
        "        temp_labels = labels[attention_masks == 1]\n",
        "        temp_output = labels[attention_masks == 1]\n",
        "        f1.update(temp_labels, temp_output)\n",
        "        #pr_curve.update(temp_output, temp_labels)\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "        labels = labels.float()\n",
        "\n",
        "\n",
        "        total += (labels.size(0) * len(labels[0]))\n",
        "        correct += (output == labels).sum()\n",
        "        #print(correct, total)\n",
        "accuracy = 100 * correct / total\n",
        "#print('Accuracy: {}'.format(accuracy))\n",
        "#precisions, recalls, thresholds = pr_curve.compute()\n",
        "f1_score = f1.compute()\n",
        "print(f1_score)\n",
        "#print(precisions)\n",
        "#print(recalls)\n",
        "#print(thresholds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pc8K4-QGgY6F",
        "outputId": "5f002550-76d1-4e87-bd91-a1c77d88fbfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1., device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L7zK4I9i5MOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example = \"I didn't ask them to make it hotter, but maybe that would solve the temp problem, sometimes asking will get you far.\"\n",
        "def process(example):\n",
        "    input_ids = tokenizer.encode(example)\n",
        "    if len(input_ids) > 512:\n",
        "      input_ids = input_ids[:512]\n",
        "    example = [torch.tensor(seq) for seq in input_ids]\n",
        "    example = [example]\n",
        "    example = torch.tensor(example)\n",
        "    example = example.to(device)\n",
        "    output = model(example)\n",
        "    output = output.logits\n",
        "    output = output.argmax(dim=-1)\n",
        "    output = output.float()\n",
        "    output = output.tolist()[0]\n",
        "    output = list(map(int, output))\n",
        "    return output\n",
        "\n",
        "print(process(example))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWLXwjnfgY86",
        "outputId": "0fae50c1-0954-4c03-dad7-76479bb252ab"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "counter = 0\n",
        "for i, (instance, actual) in enumerate(zip(valid_data, val_labels)):\n",
        "    actual = list(actual)\n",
        "    actual = list(map(int, actual))\n",
        "    actual = actual[1: len(actual) - 1]\n",
        "    predicted = process(instance)\n",
        "    predicted = predicted[1: len(predicted) - 1]\n",
        "    inst_tokens = tokenizer.tokenize(instance)\n",
        "    predicted = [(tok, inst_tokens[ind]) if i != 0 else (tok) for ind, tok in enumerate(predicted)]\n",
        "    actual = [(tok, inst_tokens[ind]) if i != 0 else (tok) for ind, tok in enumerate(actual)]\n",
        "    if predicted != actual:\n",
        "      counter += 1\n",
        "      print(i, instance)\n",
        "      print(\"Predicted\", predicted)\n",
        "      print(\"Actual   \", actual)\n",
        "      print(\"---------\")\n",
        "      \n",
        "  "
      ],
      "metadata": {
        "id": "0wqalGO8gZAb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "634f2804-f0a5-4d73-8143-06b41bdd9aa9"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27 Booking tip: there are always good deals at the beginning and end of the season which we managed to pick up both times.\n",
            "Predicted [(0, 'Book'), (0, '##ing'), (0, 'tip'), (0, ':'), (0, 'there'), (0, 'are'), (0, 'always'), (0, 'good'), (0, 'deals'), (0, 'at'), (0, 'the'), (0, 'beginning'), (0, 'and'), (0, 'end'), (0, 'of'), (0, 'the'), (0, 'season'), (0, 'which'), (0, 'we'), (1, 'managed'), (0, 'to'), (0, 'pick'), (0, 'up'), (0, 'both'), (0, 'times'), (0, '.')]\n",
            "Actual    [(0, 'Book'), (0, '##ing'), (0, 'tip'), (0, ':'), (0, 'there'), (0, 'are'), (0, 'always'), (0, 'good'), (0, 'deals'), (0, 'at'), (0, 'the'), (0, 'beginning'), (0, 'and'), (0, 'end'), (0, 'of'), (0, 'the'), (0, 'season'), (0, 'which'), (0, 'we'), (0, 'managed'), (0, 'to'), (0, 'pick'), (0, 'up'), (0, 'both'), (0, 'times'), (0, '.')]\n",
            "---------\n",
            "47 I wouldn't have been critical of the show in front of us, if the food was at least decent.\n",
            "Predicted [(0, 'I'), (1, 'wouldn'), (0, \"'\"), (0, 't'), (0, 'have'), (0, 'been'), (0, 'critical'), (0, 'of'), (0, 'the'), (0, 'show'), (0, 'in'), (0, 'front'), (0, 'of'), (0, 'us'), (0, ','), (0, 'if'), (0, 'the'), (0, 'food'), (0, 'was'), (0, 'at'), (0, 'least'), (0, 'decent'), (0, '.')]\n",
            "Actual    [(0, 'I'), (0, 'wouldn'), (0, \"'\"), (0, 't'), (0, 'have'), (0, 'been'), (0, 'critical'), (0, 'of'), (0, 'the'), (0, 'show'), (0, 'in'), (0, 'front'), (0, 'of'), (0, 'us'), (0, ','), (0, 'if'), (0, 'the'), (0, 'food'), (0, 'was'), (0, 'at'), (0, 'least'), (0, 'decent'), (0, '.')]\n",
            "---------\n",
            "50 Overall a strange disappointing stay and to top it off I chose to celebrate my birthday here, this place needs some money spent on maintenance and some visible management to look after guests and to make sure their requests are met, we won't be returning should this ever happen!\n",
            "Predicted [(0, 'Overall'), (0, 'a'), (0, 'strange'), (0, 'disappointing'), (0, 'stay'), (0, 'and'), (0, 'to'), (0, 'top'), (0, 'it'), (0, 'off'), (0, 'I'), (0, 'chose'), (0, 'to'), (0, 'celebrate'), (0, 'my'), (0, 'birthday'), (0, 'here'), (0, ','), (0, 'this'), (0, 'place'), (0, 'needs'), (0, 'some'), (0, 'money'), (0, 'spent'), (0, 'on'), (0, 'maintenance'), (0, 'and'), (0, 'some'), (0, 'visible'), (0, 'management'), (0, 'to'), (0, 'look'), (0, 'after'), (0, 'guests'), (0, 'and'), (0, 'to'), (0, 'make'), (0, 'sure'), (0, 'their'), (0, 'requests'), (0, 'are'), (0, 'met'), (0, ','), (0, 'we'), (1, 'won'), (1, \"'\"), (1, 't'), (0, 'be'), (0, 'returning'), (0, 'should'), (0, 'this'), (0, 'ever'), (0, 'happen'), (0, '!')]\n",
            "Actual    [(0, 'Overall'), (0, 'a'), (0, 'strange'), (0, 'disappointing'), (0, 'stay'), (0, 'and'), (0, 'to'), (0, 'top'), (0, 'it'), (0, 'off'), (0, 'I'), (0, 'chose'), (0, 'to'), (0, 'celebrate'), (0, 'my'), (0, 'birthday'), (0, 'here'), (0, ','), (0, 'this'), (0, 'place'), (0, 'needs'), (0, 'some'), (0, 'money'), (0, 'spent'), (0, 'on'), (0, 'maintenance'), (0, 'and'), (0, 'some'), (0, 'visible'), (0, 'management'), (0, 'to'), (0, 'look'), (0, 'after'), (0, 'guests'), (0, 'and'), (0, 'to'), (0, 'make'), (0, 'sure'), (0, 'their'), (0, 'requests'), (0, 'are'), (0, 'met'), (0, ','), (0, 'we'), (1, 'won'), (1, \"'\"), (1, 't'), (0, 'be'), (0, 'returning'), (1, 'should'), (0, 'this'), (0, 'ever'), (0, 'happen'), (0, '!')]\n",
            "---------\n",
            "68 Service was great and David couldn't have been more charming.\n",
            "Predicted [(0, 'Service'), (0, 'was'), (0, 'great'), (0, 'and'), (0, 'David'), (1, 'couldn'), (0, \"'\"), (0, 't'), (0, 'have'), (0, 'been'), (0, 'more'), (0, 'charming'), (0, '.')]\n",
            "Actual    [(0, 'Service'), (0, 'was'), (0, 'great'), (0, 'and'), (0, 'David'), (0, 'couldn'), (0, \"'\"), (0, 't'), (0, 'have'), (0, 'been'), (0, 'more'), (0, 'charming'), (0, '.')]\n",
            "---------\n",
            "83 got very very busy at the weekend as i think there must have been weekend stays coming in but in the week you could find a bed no problem, we used the terrace up by the kids pools which was fine.\n",
            "Predicted [(0, 'got'), (0, 'very'), (0, 'very'), (0, 'busy'), (0, 'at'), (0, 'the'), (0, 'weekend'), (0, 'as'), (0, 'i'), (0, 'think'), (0, 'there'), (1, 'must'), (0, 'have'), (0, 'been'), (0, 'weekend'), (0, 'stays'), (0, 'coming'), (0, 'in'), (0, 'but'), (0, 'in'), (0, 'the'), (0, 'week'), (0, 'you'), (1, 'could'), (0, 'find'), (0, 'a'), (0, 'bed'), (0, 'no'), (0, 'problem'), (0, ','), (0, 'we'), (0, 'used'), (0, 'the'), (0, 'terrace'), (0, 'up'), (0, 'by'), (0, 'the'), (0, 'kids'), (0, 'pools'), (0, 'which'), (0, 'was'), (0, 'fine'), (0, '.')]\n",
            "Actual    [(0, 'got'), (0, 'very'), (0, 'very'), (0, 'busy'), (0, 'at'), (0, 'the'), (0, 'weekend'), (0, 'as'), (0, 'i'), (0, 'think'), (0, 'there'), (0, 'must'), (0, 'have'), (0, 'been'), (0, 'weekend'), (0, 'stays'), (0, 'coming'), (0, 'in'), (0, 'but'), (0, 'in'), (0, 'the'), (0, 'week'), (0, 'you'), (1, 'could'), (0, 'find'), (0, 'a'), (0, 'bed'), (0, 'no'), (0, 'problem'), (0, ','), (0, 'we'), (0, 'used'), (0, 'the'), (0, 'terrace'), (0, 'up'), (0, 'by'), (0, 'the'), (0, 'kids'), (0, 'pools'), (0, 'which'), (0, 'was'), (0, 'fine'), (0, '.')]\n",
            "---------\n",
            "88 may have been 4* at one time but not now.\n",
            "Predicted [(1, 'may'), (0, 'have'), (0, 'been'), (0, '4'), (0, '*'), (0, 'at'), (0, 'one'), (0, 'time'), (0, 'but'), (0, 'not'), (0, 'now'), (0, '.')]\n",
            "Actual    [(0, 'may'), (0, 'have'), (0, 'been'), (0, '4'), (0, '*'), (0, 'at'), (0, 'one'), (0, 'time'), (0, 'but'), (0, 'not'), (0, 'now'), (0, '.')]\n",
            "---------\n",
            "105 Make sure to tip them, el Diablo from the lobby and his gang are great to hang around with.\n",
            "Predicted [(0, 'Make'), (0, 'sure'), (0, 'to'), (0, 'tip'), (0, 'them'), (0, ','), (0, 'el'), (0, 'Di'), (0, '##ab'), (0, '##lo'), (0, 'from'), (0, 'the'), (0, 'lobby'), (0, 'and'), (0, 'his'), (0, 'gang'), (0, 'are'), (0, 'great'), (0, 'to'), (0, 'hang'), (0, 'around'), (0, 'with'), (0, '.')]\n",
            "Actual    [(0, 'Make'), (0, 'sure'), (0, 'to'), (0, 'tip'), (0, 'them'), (0, ','), (0, 'el'), (0, 'Di'), (0, '##ab'), (0, '##lo'), (0, 'from'), (0, 'the'), (0, 'lobby'), (0, 'and'), (0, 'his'), (0, 'gang'), (0, 'are'), (1, 'great'), (0, 'to'), (0, 'hang'), (0, 'around'), (0, 'with'), (0, '.')]\n",
            "---------\n",
            "129 We visited the resort onsite doctor twice - he is such an awesome guy - once for my husband who got a rash from wearing a life jacket without a t-shirt (always wear a tshirt!!)\n",
            "Predicted [(0, 'We'), (0, 'visited'), (0, 'the'), (0, 'resort'), (0, 'on'), (0, '##site'), (0, 'doctor'), (0, 'twice'), (0, '-'), (0, 'he'), (0, 'is'), (0, 'such'), (0, 'an'), (0, 'awesome'), (0, 'guy'), (0, '-'), (0, 'once'), (0, 'for'), (0, 'my'), (0, 'husband'), (0, 'who'), (0, 'got'), (0, 'a'), (0, 'r'), (0, '##ash'), (0, 'from'), (0, 'wearing'), (0, 'a'), (0, 'life'), (0, 'jacket'), (0, 'without'), (0, 'a'), (0, 't'), (0, '-'), (0, 'shirt'), (0, '('), (0, 'always'), (0, 'wear'), (0, 'a'), (0, 't'), (0, '##shirt'), (0, '!'), (0, '!'), (0, ')')]\n",
            "Actual    [(0, 'We'), (0, 'visited'), (0, 'the'), (0, 'resort'), (0, 'on'), (0, '##site'), (0, 'doctor'), (0, 'twice'), (0, '-'), (0, 'he'), (0, 'is'), (0, 'such'), (0, 'an'), (0, 'awesome'), (0, 'guy'), (0, '-'), (1, 'once'), (0, 'for'), (0, 'my'), (0, 'husband'), (0, 'who'), (0, 'got'), (0, 'a'), (0, 'r'), (0, '##ash'), (0, 'from'), (0, 'wearing'), (0, 'a'), (0, 'life'), (0, 'jacket'), (0, 'without'), (0, 'a'), (0, 't'), (0, '-'), (0, 'shirt'), (0, '('), (0, 'always'), (0, 'wear'), (0, 'a'), (0, 't'), (0, '##shirt'), (0, '!'), (0, '!'), (0, ')')]\n",
            "---------\n",
            "196 Air conditioning was very noisy, so it was really lucky it wasn't very hot, as you could not really sleep with it on.\n",
            "Predicted [(0, 'Air'), (0, 'conditioning'), (0, 'was'), (0, 'very'), (0, 'noisy'), (0, ','), (0, 'so'), (0, 'it'), (0, 'was'), (0, 'really'), (1, 'lucky'), (0, 'it'), (0, 'wasn'), (0, \"'\"), (0, 't'), (0, 'very'), (0, 'hot'), (0, ','), (0, 'as'), (0, 'you'), (1, 'could'), (1, 'not'), (0, 'really'), (0, 'sleep'), (0, 'with'), (0, 'it'), (0, 'on'), (0, '.')]\n",
            "Actual    [(0, 'Air'), (0, 'conditioning'), (0, 'was'), (0, 'very'), (0, 'noisy'), (0, ','), (0, 'so'), (0, 'it'), (0, 'was'), (0, 'really'), (0, 'lucky'), (0, 'it'), (0, 'wasn'), (0, \"'\"), (0, 't'), (0, 'very'), (0, 'hot'), (0, ','), (0, 'as'), (0, 'you'), (1, 'could'), (1, 'not'), (0, 'really'), (0, 'sleep'), (0, 'with'), (0, 'it'), (0, 'on'), (0, '.')]\n",
            "---------\n",
            "202 I tried room service, beach diamond club bar and restaurant, buffet, the pool bar called munchies and all were good.\n",
            "Predicted [(0, 'I'), (1, 'tried'), (0, 'room'), (0, 'service'), (0, ','), (0, 'beach'), (0, 'diamond'), (0, 'club'), (0, 'bar'), (0, 'and'), (0, 'restaurant'), (0, ','), (0, 'b'), (0, '##uff'), (0, '##et'), (0, ','), (0, 'the'), (0, 'pool'), (0, 'bar'), (0, 'called'), (0, 'm'), (0, '##unch'), (0, '##ies'), (0, 'and'), (0, 'all'), (0, 'were'), (0, 'good'), (0, '.')]\n",
            "Actual    [(0, 'I'), (0, 'tried'), (0, 'room'), (0, 'service'), (0, ','), (0, 'beach'), (0, 'diamond'), (0, 'club'), (0, 'bar'), (0, 'and'), (0, 'restaurant'), (0, ','), (0, 'b'), (0, '##uff'), (0, '##et'), (0, ','), (0, 'the'), (0, 'pool'), (0, 'bar'), (0, 'called'), (0, 'm'), (0, '##unch'), (0, '##ies'), (0, 'and'), (0, 'all'), (0, 'were'), (0, 'good'), (0, '.')]\n",
            "---------\n",
            "214 Check in was quick & easy and of course accompanied by a welcome drink.\n",
            "Predicted [(0, 'Check'), (0, 'in'), (0, 'was'), (0, 'quick'), (0, '&'), (0, 'easy'), (0, 'and'), (0, 'of'), (0, 'course'), (0, 'accompanied'), (0, 'by'), (0, 'a'), (0, 'welcome'), (0, 'drink'), (0, '.')]\n",
            "Actual    [(0, 'Check'), (0, 'in'), (0, 'was'), (1, 'quick'), (0, '&'), (0, 'easy'), (0, 'and'), (0, 'of'), (0, 'course'), (0, 'accompanied'), (0, 'by'), (0, 'a'), (0, 'welcome'), (0, 'drink'), (0, '.')]\n",
            "---------\n",
            "269 Wifi was great, easy to connect and pretty strong.\n",
            "Predicted [(0, 'W'), (0, '##if'), (0, '##i'), (0, 'was'), (0, 'great'), (0, ','), (0, 'easy'), (0, 'to'), (0, 'connect'), (0, 'and'), (0, 'pretty'), (0, 'strong'), (0, '.')]\n",
            "Actual    [(0, 'W'), (0, '##if'), (0, '##i'), (0, 'was'), (0, 'great'), (0, ','), (1, 'easy'), (0, 'to'), (0, 'connect'), (0, 'and'), (0, 'pretty'), (0, 'strong'), (0, '.')]\n",
            "---------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-4b88a5063fe3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mactual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mactual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactual\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0minst_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-5c3504acac1b>\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(example)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mexample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mexample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1758\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1759\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1760\u001b[0;31m         outputs = self.bert(\n\u001b[0m\u001b[1;32m   1761\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1762\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1017\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m         )\n\u001b[0;32m-> 1019\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1020\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    607\u001b[0m                 )\n\u001b[1;32m    608\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 609\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    610\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    535\u001b[0m             \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcross_attn_present_key_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m         layer_output = apply_chunking_to_forward(\n\u001b[0m\u001b[1;32m    538\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/pytorch_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    548\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Sequence Level Validation Accuracy: {100 * (1 - (counter / len(valid_data)))}%\")"
      ],
      "metadata": {
        "id": "0eOxTzsWvruq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b86e558d-08bf-4eaa-c9da-27b6a6ec7882"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequence Level Validation Accuracy: 94.9933371406815%\n"
          ]
        }
      ]
    }
  ]
}